## Hi there ğŸ‘‹

ğŸ¤— Hello! I am Yingqing He. Nice to meet you!  
ğŸ‘¨â€ğŸ’»â€ I am a Ph.D. student at HKUST, supervised by Professor [Qifeng Chen](https://cqf.io/).    
ğŸ‘¨â€ğŸ’»â€ My research focuses on generative AI, in particular, **text-to-video generation**, **controllable visual generation**, and **multimodal generation**.   
ğŸ“« How to reach me: yhebm@connect.ust.hk  
ğŸ“£ Our lab is hiring engineering-oriented research assistants (RA). If you would like to apply, feel free to reach out with your CV!  

ğŸ§ Selected projects:  
- [![Code](https://img.shields.io/github/stars/VideoVerses/VideoTuna.svg?style=social&label=Star)](https://github.com/VideoVerses/VideoTuna) ğŸŸ **VideoTuna**: An all-in-one codebase for text-to-video applications.
- [![Code](https://img.shields.io/github/stars/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation.svg?style=social&label=Star)](https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation) ğŸ­ **Awesome-LLMs-meet-Multimodal-Generation**: A curated list of papers on LLMs-based multimodal generation (image, video, 3D, and audio).  
- [![Code](https://img.shields.io/github/stars/GuoLanqing/Awesome-High-Resolution-Diffusion.svg?style=social&label=Star)](https://github.com/GuoLanqing/Awesome-High-Resolution-Diffusion) ğŸ­ **Awesome Diffusion Models in High-Resolution Synthesis**: A curated list of papers on high-resolution image and video synthesis.
- [![Code](https://img.shields.io/github/stars/AILab-CVC/Animate-A-Story.svg?style=social&label=Star)](https://github.com/AILab-CVC/Animate-A-Story) ğŸ­ **[ECCV 2024 AI4VA Workshop] Animate-A-Story**: Storytelling with Retrieval-Augmented Video Generation.
- [![Code](https://img.shields.io/github/stars/YingqingHe/ScaleCrafter.svg?style=social&label=Star)](https://github.com/YingqingHe/ScaleCrafter) ğŸ­ **[ICLR 2024 Spotlight] Scalecrafter**: Tuning-free higher-resolution visual generation with diffusion models.
- [![Code](https://img.shields.io/github/stars/yzxing87/Seeing-and-Hearing.svg?style=social&label=Star)](https://github.com/yzxing87/Seeing-and-Hearing) ğŸ­ **[CVPR 2024] Seeing and Hearing**: Open-domain Visual-Audio Generation with Diffusion Latent Aligners.  
- [![Code](https://img.shields.io/github/stars/GuoLanqing/Self-Cascade.svg?style=social&label=Star)](https://github.com/GuoLanqing/Self-Cascade) ğŸ­ **[ECCV 2024] Make a Cheap Scaling**: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation.  
- [![Code](https://img.shields.io/github/stars/mayuelala/FollowYourPose.svg?style=social&label=Star)](https://github.com/mayuelala/FollowYourPose) ğŸ­ **[AAAI 2024] Follow-Your-Pose**: Pose-Guided Text-to-Video Generation using Pose-Free Videos.  
- [![Code](https://img.shields.io/github/stars/mayuelala/FollowYourClick.svg?style=social&label=Star)](https://github.com/mayuelala/FollowYourClick) ğŸ­ **[AAAI 2024] Follow-Your-Click**: Open-domain Regional Image Animation via Short Prompts.
- [![Code](https://img.shields.io/github/stars/AILab-CVC/VideoCrafter.svg?style=social&label=Star)](https://github.com/AILab-CVC/VideoCrafter) ğŸ­ **VideoCrafter1**: Open Diffusion Models for High-Quality Video Generation.
- [![Code](https://img.shields.io/github/stars/YingqingHe/LVDM.svg?style=social&label=Star)](https://github.com/YingqingHe/LVDM) ğŸ­ **LVDM**: Latent Video Diffusion Models for High-Fidelity Long Video Generation.
- [![Code](https://img.shields.io/github/stars/YingqingHe/Shadow-Removal-via-Generative-Priors.svg?style=social&label=Star)](https://github.com/YingqingHe/Shadow-Removal-via-Generative-Priors) ğŸ­ **[ACM MM 2021 Oral] ShadowGP**: Unsupervised portrait shadow removal via generative priors.    
For more of my generative AI projects, please check my [personal webpage](https://yingqinghe.github.io/).
